{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ab48cc",
   "metadata": {},
   "source": [
    "### Setup very simple RAG (5 liner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "838bf48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go one level up in the directories hierarchy to access src directory and codes\n",
    "import sys\n",
    "import os\n",
    "# Add project root to Python path\n",
    "project_root = os.path.abspath(\"..\")  # go one level up from notebooks/\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888547db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sanzhar\\workspace\\github.com\\kaydarovv\\ai_agent_learning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Setup necessary models for chatting and embedding\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from core.config.config import Config\n",
    "from google.genai import types\n",
    "\n",
    "Settings._llm = GoogleGenAI(\n",
    "    model = Config.CHAT_LLM,\n",
    "    api_key = Config.GOOGLE_API_KEY,\n",
    "    generation_config = types.GenerateContentConfig(\n",
    "        thinking_config = types.ThinkingConfig(thinking_budget = 0),\n",
    "        temperature = 0.2,\n",
    "    ),\n",
    "    max_tokens = 3000\n",
    ")\n",
    "\n",
    "Settings._embed_model = HuggingFaceEmbedding(\n",
    "    model_name = Config.EMBEDDING_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50496c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 23/23 [00:00<00:00, 38.69it/s]\n",
      "Generating embeddings: 100%|██████████| 30/30 [00:02<00:00, 14.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Setup simple RAG\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "docs_path = \"../documents\"\n",
    "\n",
    "# 1) Read documents and create list of 'Document' objects, that has id_, metadata, text attributes.\n",
    "#    Document class (generic container for any data source) is a subclass of the TextNode class \n",
    "documents = SimpleDirectoryReader(input_dir = docs_path).load_data()\n",
    "\n",
    "# 2) Read each of this document objects and create index from it\n",
    "#    Document objects are parsed into Node objects that have different attributes such as text, embeddings, metadata, relationships.\n",
    "#    Document objects are split into multiple nodes (relationships between these nodes are recorded in Node objects as attributes).\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents = documents,\n",
    "    show_progress = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65b8bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 16:51:20,872 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-11 16:51:22,804 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer model utilizes multi-head attention, which involves multiple parallel attention layers. Each layer, or \"head,\" performs attention on projected versions of the queries, keys, and values. The outputs of these heads are concatenated and then projected to produce the final output. This approach allows for a similar computational cost to single-head attention with full dimensionality, by using a reduced dimension for each head.\n",
      "\n",
      "Multi-head attention is applied in three main ways within the Transformer:\n",
      "*   **Encoder-decoder attention**: Queries originate from the decoder, while keys and values come from the encoder's output, enabling the decoder to attend to the entire input sequence.\n",
      "*   **Encoder self-attention**: Keys, values, and queries all stem from the output of the previous encoder layer, allowing each position in the encoder to attend to all positions in the preceding layer.\n",
      "*   **Decoder self-attention**: Similar to the encoder, but each position in the decoder can attend to all preceding positions in the decoder, including itself. To maintain the auto-regressive property, information flow is restricted to prevent attending to future positions. This is achieved by masking illegal connections within the scaled dot-product attention mechanism.\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 3) On top of that index build query engine for retrieving the context.\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# 4) Take user query and generate an answer\n",
    "user_query = \"Tell me about attention block in LLMs briefly\"\n",
    "response = query_engine.query(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa60a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 121cabbe-53e0-4f7e-8d45-4c134df53478\n",
      "Text: MultiHead(Q,K,V ) = Concat(head1,..., headh)WO where headi =\n",
      "Attention(QWQ i ,KW K i ,VW V i ) Where the projections are parameter\n",
      "matricesWQ i ∈Rdmodel×dk , WK i ∈Rdmodel×dk , WV i ∈Rdmodel×dv and WO\n",
      "∈Rhdv×dmodel . In this work we employ h = 8 parallel attention layers,\n",
      "or heads. For each of these we use dk = dv = dmodel/h= 64. Due to the\n",
      "reduc...\n",
      "Score:  0.850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieved_nodes = query_engine.retrieve(user_query)\n",
    "print(retrieved_nodes[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947dc0bf",
   "metadata": {},
   "source": [
    "### Add Qdrant database for more complicated RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e0639c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 16:51:42,444 - INFO - HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Setup the qdrant client\n",
    "client = QdrantClient(\n",
    "    host = Config.QDRANT_URL,\n",
    "    port = Config.QDRANT_PORT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e65f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import RetrieverTool\n",
    "from llama_index.core.retrievers import RouterRetriever\n",
    "from llama_index.core.selectors import LLMMultiSelector\n",
    "from core.config.constants import RagConstants\n",
    "from core.helpers.qdrant_setup import DualSchemaQdrantVectorStore\n",
    "\n",
    "def get_router() -> RouterRetriever | None:\n",
    "    \n",
    "    retriever_tools = []\n",
    "    \n",
    "    for collection_name, colleciton_description in RagConstants.COLLECTIONS.items():\n",
    "        \n",
    "        collection_store = DualSchemaQdrantVectorStore(\n",
    "            collection_name = collection_name,\n",
    "            client = client,\n",
    "            aclient = None\n",
    "        )\n",
    "        \n",
    "        collection_index = VectorStoreIndex.from_vector_store(\n",
    "            vector_store = collection_store\n",
    "        )\n",
    "        \n",
    "        collection_retriever = collection_index.as_retriever(similarity_top_k = 5)\n",
    "        \n",
    "        collection_retriever_tool = RetrieverTool.from_defaults(\n",
    "            retriever = collection_retriever,\n",
    "            description = colleciton_description\n",
    "        )\n",
    "        \n",
    "        retriever_tools.append(collection_retriever_tool)\n",
    "        \n",
    "    router = RouterRetriever(\n",
    "        selector = LLMMultiSelector.from_defaults(\n",
    "            prompt_template_str = RagConstants.LLM_MULTI_SELECTOR_PROMPT,\n",
    "            max_outputs = 3\n",
    "        ),\n",
    "        retriever_tools = retriever_tools\n",
    "    )\n",
    "    return router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42562f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 16:54:38,650 - INFO - HTTP Request: GET http://localhost:6333/collections/grants_ru_NIck_new/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,673 - INFO - HTTP Request: GET http://localhost:6333/collections/grants_ru_NIck_new \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,684 - INFO - HTTP Request: GET http://localhost:6333/collections/kvotas_ru_new/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,712 - INFO - HTTP Request: GET http://localhost:6333/collections/kvotas_ru_new \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,730 - INFO - HTTP Request: GET http://localhost:6333/collections/grants_kk_new/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,747 - INFO - HTTP Request: GET http://localhost:6333/collections/grants_kk_new \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,755 - INFO - HTTP Request: GET http://localhost:6333/collections/kvotas_kk_new/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,761 - INFO - HTTP Request: GET http://localhost:6333/collections/kvotas_kk_new \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,769 - INFO - HTTP Request: GET http://localhost:6333/collections/non_npa_kk/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,775 - INFO - HTTP Request: GET http://localhost:6333/collections/non_npa_kk \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,787 - INFO - HTTP Request: GET http://localhost:6333/collections/non_npa_ru/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,792 - INFO - HTTP Request: GET http://localhost:6333/collections/non_npa_ru \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,799 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_204_kk/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,817 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_204_kk \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,842 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_204_ru/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,859 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_204_ru \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,882 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_326_ru/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,887 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_326_ru \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,911 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_443_ru/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,925 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_443_ru \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,935 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_443_kk/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,950 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_443_kk \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,958 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_600_ru/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,987 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_600_ru \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:38,993 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_600_kk/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:39,008 - INFO - HTTP Request: GET http://localhost:6333/collections/npa_600_kk \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:39,014 - INFO - HTTP Request: GET http://localhost:6333/collections/rct/exists \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:39,035 - INFO - HTTP Request: GET http://localhost:6333/collections/rct \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:39,039 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-11 16:54:40,858 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-11 16:54:40,862 - INFO - Selecting retriever 1: Этот набор данных предоставляет детализированную информацию о распределении государственных образовательных грантов, выделяемых в виде квот для определенных социальных категорий граждан. Данные сгруппированы по общим направлениям подготовки и показывают, какое количество грантов зарезервировано для каждой льготной категории в рамках государственного заказа на 2025-2026 учебный год..\n",
      "2025-12-11 16:54:40,916 - INFO - HTTP Request: POST http://localhost:6333/collections/kvotas_ru_new/points/query \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-12-11 16:54:40\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mcore.helpers.qdrant_setup\u001b[0m:\u001b[36mparse_to_query_result\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mPayload text content is not a string (type: <class 'NoneType'>) for point 5d5d6408-4147-5d34-bc67-622bad306982. Converting to string.\u001b[0m\n",
      "\u001b[32m2025-12-11 16:54:40\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mcore.helpers.qdrant_setup\u001b[0m:\u001b[36mparse_to_query_result\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mPayload text content is not a string (type: <class 'NoneType'>) for point 83026f62-8110-5471-8539-55365cb62d0f. Converting to string.\u001b[0m\n",
      "\u001b[32m2025-12-11 16:54:40\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mcore.helpers.qdrant_setup\u001b[0m:\u001b[36mparse_to_query_result\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mPayload text content is not a string (type: <class 'NoneType'>) for point a3abcea1-749a-5288-88ab-267e42096e49. Converting to string.\u001b[0m\n",
      "\u001b[32m2025-12-11 16:54:40\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mcore.helpers.qdrant_setup\u001b[0m:\u001b[36mparse_to_query_result\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mPayload text content is not a string (type: <class 'NoneType'>) for point 73f44fd4-354b-5f4c-b1f5-4e2e56dfb558. Converting to string.\u001b[0m\n",
      "\u001b[32m2025-12-11 16:54:40\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mcore.helpers.qdrant_setup\u001b[0m:\u001b[36mparse_to_query_result\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mPayload text content is not a string (type: <class 'NoneType'>) for point c40c44d0-9e3b-5040-9aff-3bba3baabe15. Converting to string.\u001b[0m\n",
      "2025-12-11 16:54:40,923 - INFO - Selecting retriever 3: Бұл жинақ (коллекция) квоталар, арнайы бағыттар және білім беру бағдарламалары топтары бойынша білім беру гранттарының бөлінуі туралы деректерді қамтиды..\n",
      "2025-12-11 16:54:40,955 - INFO - HTTP Request: POST http://localhost:6333/collections/kvotas_kk_new/points/query \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-12-11 16:54:40\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mcore.helpers.qdrant_setup\u001b[0m:\u001b[36mparse_to_query_result\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mPayload text content is not a string (type: <class 'NoneType'>) for point 4bfd9797-8876-5e48-b937-434e286acfa8. Converting to string.\u001b[0m\n",
      "\u001b[32m2025-12-11 16:54:40\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mcore.helpers.qdrant_setup\u001b[0m:\u001b[36mparse_to_query_result\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mPayload text content is not a string (type: <class 'NoneType'>) for point 8b3738bd-36df-50e0-8a91-4962f92e6ca3. Converting to string.\u001b[0m\n",
      "\u001b[32m2025-12-11 16:54:40\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mcore.helpers.qdrant_setup\u001b[0m:\u001b[36mparse_to_query_result\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mPayload text content is not a string (type: <class 'NoneType'>) for point 59621990-61f2-587f-9fc9-779f1b1d14b4. Converting to string.\u001b[0m\n",
      "\u001b[32m2025-12-11 16:54:40\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mcore.helpers.qdrant_setup\u001b[0m:\u001b[36mparse_to_query_result\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mPayload text content is not a string (type: <class 'NoneType'>) for point f8673da4-eba3-5631-b0c4-d02b72c1ea72. Converting to string.\u001b[0m\n",
      "\u001b[32m2025-12-11 16:54:40\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mcore.helpers.qdrant_setup\u001b[0m:\u001b[36mparse_to_query_result\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mPayload text content is not a string (type: <class 'NoneType'>) for point 7b006ee5-9d4f-5fa7-a8b3-69ea96d8cf60. Converting to string.\u001b[0m\n",
      "2025-12-11 16:54:40,960 - INFO - Selecting retriever 11: Коллекция охватывает темы образовательных грантов, квот приема для различных категорий граждан, правила приема иностранных граждан, а также включает таблицы и шкалы перевода баллов международных стандартизированных тестов (ЕНТ, SAT, ACT, IB, A Level, TOEFL, IELTS, KAZTEST) и требования к абитуриентам по областям образования, таким как 'Педагогические науки' и 'Здравоохранение'..\n",
      "2025-12-11 16:54:40,992 - INFO - HTTP Request: POST http://localhost:6333/collections/npa_600_ru/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "input_query = \"Расскажи мне про квоты\"\n",
    "router = get_router().retrieve(input_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
